{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc142f9f-ea28-4c55-b2cf-4de247b3daa7",
   "metadata": {},
   "source": [
    "# Imports + Cache Loader + Cycle Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c52efc-d459-4894-b0b7-28ed645adc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pyreadstat\n",
    "\n",
    "# Cache directory\n",
    "CACHE_DIR = \"nhanes_cache\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------\n",
    "# Helper: Load NHANES XPT with caching\n",
    "# ---------------------------------------\n",
    "def load_nhanes_xpt(filename: str, year: str):\n",
    "    local_path = os.path.join(CACHE_DIR, f\"{year}_{filename}\")\n",
    "\n",
    "    if os.path.exists(local_path):\n",
    "        df, meta = pyreadstat.read_xport(local_path)\n",
    "        return df\n",
    "\n",
    "    url = f\"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/{year}/DataFiles/{filename}\"\n",
    "    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "    if r.status_code == 404:\n",
    "        print(f\"Missing: {filename} for {year}\")\n",
    "        return None\n",
    "\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "    df, meta = pyreadstat.read_xport(local_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Cycle file dictionaries (2011–2018)\n",
    "# ---------------------------------------\n",
    "def cycle(year, suffix):\n",
    "    return {\n",
    "        \"DEMO\":   f\"DEMO_{suffix}.xpt\",\n",
    "        \"HDL\":    f\"HDL_{suffix}.xpt\",\n",
    "        \"TCHOL\":  f\"TCHOL_{suffix}.xpt\",\n",
    "        \"TRIGLY\": f\"TRIGLY_{suffix}.xpt\",\n",
    "        \"GLU\":    f\"GLU_{suffix}.xpt\",\n",
    "        \"INS\":    f\"INS_{suffix}.xpt\" if suffix != \"G\" else \"GLU_G.xpt\",\n",
    "        \"DPQ\":    f\"DPQ_{suffix}.xpt\",\n",
    "        \"SLQ\":    f\"SLQ_{suffix}.xpt\",\n",
    "        \"DR1TOT\": f\"DR1TOT_{suffix}.xpt\",\n",
    "        \"PAQ\":    f\"PAQ_{suffix}.xpt\",\n",
    "        \"BPX\":    f\"BPX_{suffix}.xpt\",\n",
    "        \"BIOPRO\": f\"BIOPRO_{suffix}.xpt\",      # ALT/AST in some cycles\n",
    "        \"ALB_CR\": f\"ALB_CR_{suffix}.xpt\",\n",
    "        \"BMX\":    f\"BMX_{suffix}.xpt\",          # BMI/waist\n",
    "        \"CBC\":    f\"CBC_{suffix}.xpt\",\n",
    "    }\n",
    "\n",
    "all_cycles = {\n",
    "    \"2011\": cycle(\"2011\", \"G\"),\n",
    "    \"2013\": cycle(\"2013\", \"H\"),\n",
    "    \"2015\": cycle(\"2015\", \"I\"),\n",
    "    \"2017\": cycle(\"2017\", \"J\"),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eb3089-aefa-4c9b-886f-a79c9168387d",
   "metadata": {},
   "source": [
    "# Merge NHANES Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8340fe-613e-4572-b7dc-be5497c4efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cycle(files: dict, year: str):\n",
    "    dfs = []\n",
    "    for name, fname in files.items():\n",
    "        d = load_nhanes_xpt(fname, year)\n",
    "        if d is not None:\n",
    "            dfs.append(d)\n",
    "\n",
    "    if not dfs:\n",
    "        return None\n",
    "\n",
    "    merged = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        merged = merged.merge(d, on=\"SEQN\", how=\"outer\")\n",
    "\n",
    "    merged[\"CYCLE\"] = year\n",
    "    return merged\n",
    "\n",
    "\n",
    "df_list = []\n",
    "for yr, files in all_cycles.items():\n",
    "    print(f\"Loading cycle {yr} ...\")\n",
    "    out = load_cycle(files, yr)\n",
    "    if out is not None:\n",
    "        df_list.append(out)\n",
    "\n",
    "df_all = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Merged NHANES shape:\", df_all.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e487d83-931a-4978-8aac-4e527df8c39b",
   "metadata": {},
   "source": [
    "# Harmonization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b91528-528f-43bc-8588-f028657980a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------\n",
    "# Demographics\n",
    "# ----------------------------------\n",
    "def harmonize_demographics(df):\n",
    "    out = df.copy()\n",
    "    out[\"age\"] = out.get(\"RIDAGEYR\", np.nan)\n",
    "    out[\"sex\"] = out[\"RIAGENDR\"].map({1: \"Male\", 2: \"Female\"}) if \"RIAGENDR\" in out else np.nan\n",
    "    out[\"pir\"] = out.get(\"INDFMPIR\", np.nan)\n",
    "    out[\"race_ethnicity\"] = out.get(\"RIDRETH3\", np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Blood Pressure\n",
    "# ----------------------------------\n",
    "def harmonize_bp(df):\n",
    "    out = df.copy()\n",
    "    sbp_cols = [c for c in out if c.startswith(\"BPXSY\")]\n",
    "    dbp_cols = [c for c in out if c.startswith(\"BPXDI\")]\n",
    "\n",
    "    out[\"sbp\"] = out[sbp_cols].mean(axis=1) if sbp_cols else np.nan\n",
    "    out[\"dbp\"] = out[dbp_cols].mean(axis=1) if dbp_cols else np.nan\n",
    "    out[\"pulse_pressure\"] = out[\"sbp\"] - out[\"dbp\"]\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Lipids\n",
    "# ----------------------------------\n",
    "def harmonize_lipids(df):\n",
    "    out = df.copy()\n",
    "    out[\"hdl\"] = out.get(\"LBDHDD\", np.nan)\n",
    "    out[\"tc\"]  = out.get(\"LBXTC\", np.nan)\n",
    "    out[\"tg\"]  = out.get(\"LBXTR\", np.nan)\n",
    "\n",
    "    if \"LBXTC\" in out and \"LBDHDD\" in out:\n",
    "        out[\"ldl\"] = out[\"LBXTC\"] - out[\"LBDHDD\"] - (out[\"LBXTR\"] / 5)\n",
    "    else:\n",
    "        out[\"ldl\"] = np.nan\n",
    "\n",
    "    out[\"apob_est\"] = 0.65 * out[\"tc\"] - 0.59 * out[\"hdl\"]\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Renal\n",
    "# ----------------------------------\n",
    "def harmonize_renal(df):\n",
    "    out = df.copy()\n",
    "    out[\"creat_mg_dl\"] = out.get(\"LBXSCR\", np.nan)\n",
    "    out[\"egfr\"] = 175 * (out[\"creat_mg_dl\"] ** -1.154) * 1.018\n",
    "    out[\"acr\"] = out.get(\"URXUM\", np.nan) / out.get(\"URXCRS\", np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Metabolic\n",
    "# ----------------------------------\n",
    "def harmonize_metabolic(df):\n",
    "    out = df.copy()\n",
    "    out[\"glucose\"] = out.get(\"LBXGLU\", np.nan)\n",
    "    out[\"insulin\"] = out.get(\"LBXINS\", np.nan)\n",
    "    out[\"homa_ir\"] = (out[\"glucose\"] * out[\"insulin\"]) / 405\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Sleep\n",
    "# ----------------------------------\n",
    "def harmonize_sleep(df):\n",
    "    out = df.copy()\n",
    "    out[\"sleep_hours\"] = out.get(\"SLD010H\", np.nan)\n",
    "    out[\"sleep_trouble\"] = out.get(\"SLQ050\", np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# PHQ-9\n",
    "# ----------------------------------\n",
    "def harmonize_phq(df):\n",
    "    out = df.copy()\n",
    "    phq_cols = [c for c in out.columns if c.startswith(\"DPQ0\")]\n",
    "    if phq_cols:\n",
    "        out[\"phq9\"] = out[phq_cols].sum(axis=1)\n",
    "    else:\n",
    "        out[\"phq9\"] = np.nan\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# PA days + index\n",
    "# ----------------------------------\n",
    "def harmonize_physical_activity_days(df):\n",
    "    out = df.copy()\n",
    "    out[\"pa_vigorous_days\"] = out.get(\"PAQ650\", np.nan)\n",
    "    out[\"pa_moderate_days\"] = out.get(\"PAQ665\", np.nan)\n",
    "    out[\"pa_walk_days\"]     = out.get(\"PAQ670\", np.nan)\n",
    "\n",
    "    out[\"pa_index\"] = (\n",
    "        2*out[\"pa_vigorous_days\"]\n",
    "        + out[\"pa_moderate_days\"]\n",
    "        + 0.5*out[\"pa_walk_days\"]\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# Diet (food groups)\n",
    "# ----------------------------------\n",
    "def harmonize_diet(df):\n",
    "    out = df.copy()\n",
    "    diet_map = {\n",
    "        \"whole_grains\": \"DR1TWHL\",\n",
    "        \"refined_grains\": \"DR1TGR\",\n",
    "        \"nuts_seeds\": \"DR1TNS\",\n",
    "        \"legumes\": \"DR1TLEG\",\n",
    "        \"low_fat_dairy\": \"DR1TDLF\",\n",
    "        \"fish\": \"DR1TFISH\",\n",
    "        \"red_meat\": \"DR1TREDM\",\n",
    "        \"processed_meat\": \"DR1TPRM\",\n",
    "        \"other_fruit\": \"DR1TFRT\",\n",
    "        \"citrus_melons_berries\": \"DR1TCITM\",\n",
    "        \"dark_green_veg\": \"DR1TVEG1\",\n",
    "        \"other_veg\": \"DR1TVEG2\",\n",
    "        \"ssb\": \"DR1TSSB\",\n",
    "        \"fried_foods\": \"DR1TFF\",\n",
    "    }\n",
    "    for new, old in diet_map.items():\n",
    "        out[new] = out.get(old, np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# BMI + waist\n",
    "# ----------------------------------\n",
    "def harmonize_additional(df):\n",
    "    out = df.copy()\n",
    "    out[\"bmi\"]   = out.get(\"BMXBMI\", np.nan)\n",
    "    out[\"waist\"] = out.get(\"BMXWAIST\", np.nan)\n",
    "    return out\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# ALT / AST + CBC\n",
    "# ----------------------------------\n",
    "def harmonize_liver_and_cbc(df):\n",
    "    out = df.copy()\n",
    "\n",
    "    # ALT\n",
    "    for col in [\"LBXALT\",\"LBDALT\",\"LBDALTSI\",\"LBXSAT\",\"LBXSATSI\",\"LBXSAPSI\"]:\n",
    "        if col in out:\n",
    "            out[\"alt\"] = out[col]\n",
    "            break\n",
    "    else:\n",
    "        out[\"alt\"] = np.nan\n",
    "\n",
    "    # AST\n",
    "    for col in [\"LBXAST\",\"LBDAST\",\"LBDASSI\",\"LBXSAS\",\"LBXSASSI\"]:\n",
    "        if col in out:\n",
    "            out[\"ast\"] = out[col]\n",
    "            break\n",
    "    else:\n",
    "        out[\"ast\"] = np.nan\n",
    "\n",
    "    # Hemoglobin\n",
    "    out[\"hemoglobin\"] = out.get(\"LBXHGB\", np.nan)\n",
    "\n",
    "    # WBC\n",
    "    out[\"wbc\"] = out.get(\"LBXWBCSI\", out.get(\"LBXWBC\", np.nan))\n",
    "\n",
    "    # Platelets\n",
    "    out[\"platelets\"] = out.get(\"LBXPLTSI\", out.get(\"LBXPLT\", np.nan))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86cfe8-304f-4e2d-92ef-32fb80bb4e5f",
   "metadata": {},
   "source": [
    "# Master Harmonization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854da1f-2a5f-4912-ad9c-c8a3f0361016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_nhanes(df):\n",
    "    return (\n",
    "        df\n",
    "        .pipe(harmonize_demographics)\n",
    "        .pipe(harmonize_bp)\n",
    "        .pipe(harmonize_lipids)\n",
    "        .pipe(harmonize_renal)\n",
    "        .pipe(harmonize_metabolic)\n",
    "        .pipe(harmonize_sleep)\n",
    "        .pipe(harmonize_phq)\n",
    "        .pipe(harmonize_physical_activity_days)\n",
    "        .pipe(harmonize_diet)\n",
    "        .pipe(harmonize_liver_and_cbc)\n",
    "        .pipe(harmonize_additional)\n",
    "    )\n",
    "\n",
    "df_h = prepare_nhanes(df_all)\n",
    "print(df_h.shape)\n",
    "\n",
    "df_h[[\"bmi\",\"waist\",\"alt\",\"ast\",\"wbc\",\"hemoglobin\",\"platelets\"]].notna().mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294912d6-140c-42f2-a541-8e9cea4e4af7",
   "metadata": {},
   "source": [
    "# Variable-level GGM (Biovista backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13294535-25ff-4205-9fcc-1a77cb12c63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import GraphicalLasso\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Define system → variable map for variable-level GGM\n",
    "# -------------------------------------------------------\n",
    "physio_systems_ggm = {\n",
    "    \"Demographics\": [\"age\", \"pir\"],\n",
    "\n",
    "    \"Lipids\": [\"hdl\", \"tc\", \"tg\", \"ldl\", \"apob_est\"],\n",
    "\n",
    "    \"Metabolic\": [\n",
    "        \"glucose\", \"insulin\", \"homa_ir\",\n",
    "        \"bmi\", \"waist\"\n",
    "    ],\n",
    "\n",
    "    \"Blood_Pressure\": [\"sbp\", \"dbp\", \"pulse_pressure\"],\n",
    "\n",
    "    \"Renal\": [\"creat_mg_dl\", \"egfr\", \"acr\"],\n",
    "\n",
    "    \"Liver\": [\"alt\", \"ast\"],\n",
    "\n",
    "    \"Inflammation\": [\"wbc\"],\n",
    "\n",
    "    \"Hematologic\": [\"hemoglobin\", \"platelets\"],\n",
    "\n",
    "    \"Sleep\": [\"sleep_hours\", \"sleep_trouble\"],\n",
    "\n",
    "    \"Mental_Health\": [\"phq9\"],\n",
    "\n",
    "    \"Physical_Activity\": [\n",
    "        \"pa_vigorous_days\", \"pa_moderate_days\",\n",
    "        \"pa_walk_days\", \"pa_index\"\n",
    "    ],\n",
    "\n",
    "    \"Diet\": [\n",
    "        \"whole_grains\", \"refined_grains\", \"nuts_seeds\", \"legumes\",\n",
    "        \"low_fat_dairy\", \"fish\", \"red_meat\", \"processed_meat\",\n",
    "        \"other_fruit\", \"citrus_melons_berries\", \"dark_green_veg\",\n",
    "        \"other_veg\", \"ssb\", \"fried_foods\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Flatten & filter by missingness ≥ 40%\n",
    "# -------------------------------------------------------\n",
    "all_vars = sum(physio_systems_ggm.values(), [])\n",
    "all_vars = [v for v in all_vars if v in df_h.columns]\n",
    "\n",
    "nonmissing_frac = df_h[all_vars].notna().mean()\n",
    "vars_use = nonmissing_frac[nonmissing_frac >= 0.40].index.tolist()\n",
    "\n",
    "print(\"Variables used in variable-level GGM:\", len(vars_use))\n",
    "print(vars_use)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Impute + standardize\n",
    "# -------------------------------------------------------\n",
    "X = df_h[vars_use].to_numpy(float)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imp = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_imp)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Fit Graphical Lasso\n",
    "# -------------------------------------------------------\n",
    "ggm_model = GraphicalLasso(alpha=0.15, max_iter=200)\n",
    "ggm_model.fit(X_std)\n",
    "\n",
    "precision = ggm_model.precision_.copy()\n",
    "\n",
    "# Partial correlations\n",
    "diag = np.sqrt(np.diag(precision))\n",
    "outer = np.outer(diag, diag)\n",
    "partial_corr = -precision / outer\n",
    "np.fill_diagonal(partial_corr, 0.0)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Build NetworkX graph\n",
    "# -------------------------------------------------------\n",
    "G_var = nx.Graph()\n",
    "\n",
    "# Map variable → system\n",
    "var_to_system = {}\n",
    "for system, var_list in physio_systems_ggm.items():\n",
    "    for v in var_list:\n",
    "        if v in vars_use:\n",
    "            var_to_system[v] = system\n",
    "\n",
    "# Add nodes\n",
    "for v in vars_use:\n",
    "    G_var.add_node(v, system=var_to_system.get(v, \"Other\"))\n",
    "\n",
    "# Add edges with small threshold\n",
    "edge_threshold = 0.10\n",
    "for i, vi in enumerate(vars_use):\n",
    "    for j in range(i + 1, len(vars_use)):\n",
    "        vj = vars_use[j]\n",
    "        w = partial_corr[i, j]\n",
    "        if abs(w) >= edge_threshold:\n",
    "            G_var.add_edge(vi, vj, weight=w)\n",
    "\n",
    "print(f\"Variable-level GGM: {G_var.number_of_nodes()} nodes, {G_var.number_of_edges()} edges\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. Layout for consistent plotting\n",
    "# -------------------------------------------------------\n",
    "pos_var = nx.spring_layout(G_var, seed=1, k=0.35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618ddf5-95a3-497e-b712-53f7d3dd2bd7",
   "metadata": {},
   "source": [
    "# Create a simulated “interesting” patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7cc24-429b-4119-a5ab-018d4148c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 1. Population mean & SD for these variables\n",
    "# -------------------------------------------------------\n",
    "df_desc = df_h[vars_use].describe()\n",
    "mu = df_desc.loc[\"mean\"]\n",
    "sd = df_desc.loc[\"std\"].replace(0, np.nan)   # guard against divide-by-zero\n",
    "\n",
    "# Start at mean\n",
    "patient_vals = mu.copy()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Make an \"interesting\" patient (abnormal in several systems)\n",
    "#    (You can tweak these z-values to taste.)\n",
    "# -------------------------------------------------------\n",
    "z_overrides = {\n",
    "    # Lipids / metabolic\n",
    "    \"apob_est\": +2.0,\n",
    "    \"hdl\": -1.5,\n",
    "    \"tg\": +2.0,\n",
    "    \"glucose\": +2.0,\n",
    "    \"insulin\": +2.0,\n",
    "    \"homa_ir\": +2.5,\n",
    "    \"bmi\": +2.0,\n",
    "    \"waist\": +2.0,\n",
    "\n",
    "    # BP\n",
    "    \"sbp\": +1.5,\n",
    "    \"dbp\": +1.0,\n",
    "\n",
    "    # Renal\n",
    "    \"egfr\": -1.0,\n",
    "    \"acr\": +1.5,\n",
    "\n",
    "    # Liver\n",
    "    \"alt\": +2.0,\n",
    "    \"ast\": +1.5,\n",
    "\n",
    "    # Inflammation / hematology\n",
    "    \"wbc\": +1.5,\n",
    "    \"hemoglobin\": -1.0,\n",
    "    \"platelets\": +1.0,\n",
    "\n",
    "    # Sleep / mental health\n",
    "    \"sleep_hours\": -1.5,\n",
    "    \"sleep_trouble\": +1.5,\n",
    "    \"phq9\": +2.0,\n",
    "\n",
    "    # Physical activity\n",
    "    \"pa_index\": -2.0,\n",
    "\n",
    "    # Diet (if present)\n",
    "    \"whole_grains\": -1.0,\n",
    "    \"red_meat\": +1.5,\n",
    "    \"ssb\": +2.0,\n",
    "\n",
    "    # Demographics\n",
    "    \"age\": +1.0,\n",
    "    \"pir\": -1.0,\n",
    "}\n",
    "\n",
    "for var, z in z_overrides.items():\n",
    "    if var in patient_vals.index and pd.notna(sd[var]):\n",
    "        patient_vals[var] = mu[var] + z * sd[var]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Variable-level z-scores for this patient\n",
    "# -------------------------------------------------------\n",
    "z_patient = (patient_vals - mu) / sd\n",
    "z_patient = z_patient.fillna(0.0)\n",
    "\n",
    "z_patient.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb83dbe-c942-40bf-8e11-3243bb27fe74",
   "metadata": {},
   "source": [
    "# Plot Biovista-style variable-level network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0494d3-6b07-4bb5-b81c-581448c00cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Pretty plotting function (variable-level Biovista)\n",
    "# -------------------------------------------------------\n",
    "system_color_map = {\n",
    "    \"Demographics\": \"#008080\",\n",
    "    \"Lipids\": \"#f1c40f\",\n",
    "    \"Metabolic\": \"#e67e22\",\n",
    "    \"Blood_Pressure\": \"#e74c3c\",\n",
    "    \"Renal\": \"#8e44ad\",\n",
    "    \"Liver\": \"#d35400\",\n",
    "    \"Inflammation\": \"#c0392b\",\n",
    "    \"Hematologic\": \"#7f8c8d\",\n",
    "    \"Sleep\": \"#3498db\",\n",
    "    \"Mental_Health\": \"#2c3e50\",\n",
    "    \"Physical_Activity\": \"#27ae60\",\n",
    "    \"Diet\": \"#16a085\",\n",
    "    \"Other\": \"#7f8c8d\",\n",
    "}\n",
    "\n",
    "def plot_biovista_patient_network(\n",
    "    G,\n",
    "    z_scores,\n",
    "    var_to_system,\n",
    "    pos,\n",
    "    title=\"Biovista Variable-Level Network (NHANES Simulation)\",\n",
    "    out_file=\"biovista_variable_patient_network.png\"\n",
    "):\n",
    "    # Attach z-scores + system labels\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n][\"z\"] = float(z_scores.get(n, 0.0))\n",
    "        G.nodes[n][\"system\"] = var_to_system.get(n, \"Other\")\n",
    "\n",
    "    z_vals = np.array([G.nodes[n][\"z\"] for n in G.nodes()])\n",
    "    z_clipped = np.clip(z_vals, -3, +3)\n",
    "\n",
    "    # Color by z-score\n",
    "    cmap = plt.cm.coolwarm\n",
    "    node_colors = cmap((z_clipped + 3) / 6)\n",
    "\n",
    "    # Size by |z|\n",
    "    node_sizes = 250 + 600 * np.abs(z_clipped)\n",
    "\n",
    "    # Edge widths by |weight|\n",
    "    edge_widths = [\n",
    "        0.4 + 3.0 * abs(d.get(\"weight\", 0.05))\n",
    "        for (_, _, d) in G.edges(data=True)\n",
    "    ]\n",
    "\n",
    "    # Node outlines by system\n",
    "    node_edgecolors = [\n",
    "        system_color_map.get(G.nodes[n][\"system\"], \"#7f8c8d\")\n",
    "        for n in G.nodes()\n",
    "    ]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        width=edge_widths,\n",
    "        alpha=0.25,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=1.2,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        font_size=7,\n",
    "        font_weight=\"bold\",\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Colorbar for z-score\n",
    "    sm = plt.cm.ScalarMappable(\n",
    "        cmap=cmap, norm=plt.Normalize(vmin=-3, vmax=3)\n",
    "    )\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.7)\n",
    "    cbar.set_label(\"Z-score (patient vs NHANES)\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(out_file, dpi=350, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8. Generate and save the figure\n",
    "# -------------------------------------------------------\n",
    "fig, ax = plot_biovista_patient_network(\n",
    "    G_var,\n",
    "    z_patient,\n",
    "    var_to_system,\n",
    "    pos_var,\n",
    "    title=\"Biovista Variable-Level Network (NHANES Simulation)\",\n",
    "    out_file=\"biovista_variable_patient_network.png\"\n",
    ")\n",
    "\n",
    "print(\"Saved: biovista_variable_patient_network.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86484ae-1927-4399-807b-cc02fee22c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Side-by-side comparison: Healthy vs Unhealthy\n",
    "# -------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Side-by-side comparison: Michael vs Daniel\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# 1. Michael (Healthy) — baseline, all z = 0\n",
    "z_Michael = pd.Series(0.0, index=z_patient.index)\n",
    "\n",
    "# 2. Daniel (Unhealthy) — your simulated patient with abnormalities\n",
    "z_Daniel = z_patient.copy()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Shared layout (identical coordinates for both)\n",
    "# -------------------------------------------------------\n",
    "pos_shared = pos_var\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Helper function (your original code, unchanged)\n",
    "# -------------------------------------------------------\n",
    "def plot_biovista_on_axes(G, z_scores, ax, title):\n",
    "    # Attach z-scores and metadata to nodes for plotting\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n][\"z\"] = float(z_scores.get(n, 0.0))\n",
    "        G.nodes[n][\"system\"] = var_to_system.get(n, \"Other\")\n",
    "\n",
    "    z_vals = np.array([G.nodes[n][\"z\"] for n in G.nodes()])\n",
    "    z_clip = np.clip(z_vals, -3, 3)\n",
    "\n",
    "    node_colors = plt.cm.coolwarm((z_clip + 3) / 6)\n",
    "    node_sizes = 250 + 600 * np.abs(z_clip)\n",
    "    node_edgecolors = [\n",
    "        system_color_map.get(G.nodes[n][\"system\"], \"#7f8c8d\") \n",
    "        for n in G.nodes()\n",
    "    ]\n",
    "    edge_widths = [\n",
    "        0.4 + 3 * abs(d.get(\"weight\", 0.05))\n",
    "        for (_, _, d) in G.edges(data=True)\n",
    "    ]\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos_shared, width=edge_widths, alpha=0.25, ax=ax)\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos_shared,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=1.2,\n",
    "        ax=ax\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos_shared,\n",
    "        font_size=7,\n",
    "        font_weight=\"bold\",\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# Final side-by-side figure\n",
    "# -------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plot_biovista_on_axes(G_var, z_Michael, axes[0], \"Michael — Healthy Network (Z = 0)\")\n",
    "plot_biovista_on_axes(G_var, z_Daniel, axes[1], \"Daniel — Multi-System Dysregulation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"biovista_michael_vs_daniel.png\", dpi=350, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: biovista_michael_vs_daniel.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740fb1b7-310e-4d94-b5df-e586acc0841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def plot_biovista_patient_network_labeled(\n",
    "    G,\n",
    "    z_scores,\n",
    "    var_to_system,\n",
    "    pos,\n",
    "    title,\n",
    "    ax\n",
    "):\n",
    "    \"\"\"\n",
    "    Draws the patient network onto a provided matplotlib axis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Attach metadata\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n][\"z\"] = float(z_scores.get(n, 0.0))\n",
    "        G.nodes[n][\"system\"] = var_to_system.get(n, \"Other\")\n",
    "\n",
    "    z_vals = np.array([G.nodes[n][\"z\"] for n in G.nodes()])\n",
    "    z_clipped = np.clip(z_vals, -3, 3)\n",
    "\n",
    "    # Color by z-score\n",
    "    cmap = plt.cm.coolwarm\n",
    "    node_colors = cmap((z_clipped + 3) / 6)\n",
    "\n",
    "    # Size by |z|\n",
    "    node_sizes = 250 + 600 * np.abs(z_clipped)\n",
    "\n",
    "    # Edge widths\n",
    "    edge_widths = [\n",
    "        0.4 + 3.0 * abs(d.get(\"weight\", 0.05))\n",
    "        for (_, _, d) in G.edges(data=True)\n",
    "    ]\n",
    "\n",
    "    # Node outlines by system\n",
    "    system_color_map = {\n",
    "        \"Demographics\": \"#008080\",\n",
    "        \"Lipids\": \"#f1c40f\",\n",
    "        \"Metabolic\": \"#e67e22\",\n",
    "        \"Blood_Pressure\": \"#e74c3c\",\n",
    "        \"Renal\": \"#8e44ad\",\n",
    "        \"Sleep\": \"#3498db\",\n",
    "        \"Mental_Health\": \"#2c3e50\",\n",
    "        \"Physical_Activity\": \"#27ae60\",\n",
    "        \"Diet\": \"#16a085\",\n",
    "        \"Other\": \"#7f8c8d\",\n",
    "    }\n",
    "\n",
    "    node_edgecolors = [\n",
    "        system_color_map.get(G.nodes[n][\"system\"], \"#7f8c8d\")\n",
    "        for n in G.nodes()\n",
    "    ]\n",
    "\n",
    "    # --- Drawing ---\n",
    "    nx.draw_networkx_edges(\n",
    "        G, pos,\n",
    "        width=edge_widths,\n",
    "        alpha=0.25,\n",
    "        ax=ax\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=1.2,\n",
    "        ax=ax\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos,\n",
    "        font_size=6.5,\n",
    "        font_weight=\"bold\",\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "#  FINAL SIDE-BY-SIDE FIGURE\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "plot_biovista_patient_network_labeled(\n",
    "    G_var,\n",
    "    z_Michael,          # your healthy z-score vector\n",
    "    var_to_system,\n",
    "    pos_var,\n",
    "    title=\"Michael — Healthy, Stable Network\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "plot_biovista_patient_network_labeled(\n",
    "    G_var,\n",
    "    z_Daniel,           # your unhealthy z-score vector\n",
    "    var_to_system,\n",
    "    pos_var,\n",
    "    title=\"Daniel — Multi-System Dysregulation\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"biovista_michael_vs_daniel.png\", dpi=350)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da64e1a-0f75-4e3f-b313-624381ce9b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Compute node degree for the variable-level graph\n",
    "# -------------------------------------------------------\n",
    "degree_dict = dict(G_var.degree())\n",
    "\n",
    "# Convert to a pandas Series for alignment\n",
    "degree_series = pd.Series(degree_dict)\n",
    "\n",
    "# Keep only variables we model\n",
    "degree_series = degree_series.loc[z_patient.index]\n",
    "\n",
    "# To avoid zero-degree division issues, add a small epsilon\n",
    "degree_series = degree_series.replace(0, 0.5)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Define the z-score vectors for each person\n",
    "# -------------------------------------------------------\n",
    "\n",
    "# Michael = healthy prototype → all zeros\n",
    "z_michael = pd.Series(0.0, index=z_patient.index)\n",
    "\n",
    "# Daniel = simulated unhealthy patient you created earlier\n",
    "z_daniel = z_patient.copy()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Network score formula\n",
    "# -------------------------------------------------------\n",
    "# Weighted absolute z-scores: |z| * degree\n",
    "def compute_network_score(z_vec, degree_vec):\n",
    "    weighted = np.abs(z_vec) * degree_vec\n",
    "    return weighted.sum()\n",
    "\n",
    "network_score_michael = compute_network_score(z_michael, degree_series)\n",
    "network_score_daniel = compute_network_score(z_daniel, degree_series)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Output comparison table\n",
    "# -------------------------------------------------------\n",
    "df_scores = pd.DataFrame({\n",
    "    \"Network Score\": [network_score_michael, network_score_daniel]\n",
    "}, index=[\"Michael (Healthy)\", \"Daniel (Unhealthy)\"])\n",
    "\n",
    "print(df_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1eb75-f01b-4087-a6e2-b45e2d2cf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to render plots separately\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "# ----------------------------\n",
    "# Helper function\n",
    "# ----------------------------\n",
    "def plot_single_biovista(\n",
    "    G,\n",
    "    z_scores,\n",
    "    var_to_system,\n",
    "    pos,\n",
    "    title,\n",
    "    out_file\n",
    "):\n",
    "    Gp = G.copy()\n",
    "\n",
    "    # Assign z-scores\n",
    "    for n in Gp.nodes():\n",
    "        Gp.nodes[n][\"z\"] = float(z_scores.get(n, 0.0))\n",
    "        Gp.nodes[n][\"system\"] = var_to_system.get(n, \"Other\")\n",
    "\n",
    "    # Extract z\n",
    "    z_vals = np.array([Gp.nodes[n][\"z\"] for n in Gp.nodes()])\n",
    "    z_clip = np.clip(z_vals, -3, 3)\n",
    "\n",
    "    cmap = plt.cm.coolwarm\n",
    "    node_colors = cmap((z_clip + 3) / 6)\n",
    "    node_sizes = 250 + 600 * np.abs(z_clip)\n",
    "    node_edgecolors = [\n",
    "        system_color_map.get(Gp.nodes[n][\"system\"], \"#7f8c8d\")\n",
    "        for n in Gp.nodes()\n",
    "    ]\n",
    "\n",
    "    edge_widths = [0.4 + 3*abs(d.get(\"weight\", 0.05))\n",
    "                   for (_,_,d) in Gp.edges(data=True)]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "    nx.draw_networkx_edges(Gp, pos, width=edge_widths, alpha=0.25, ax=ax)\n",
    "    nx.draw_networkx_nodes(\n",
    "        Gp, pos,\n",
    "        node_color=node_colors,\n",
    "        node_size=node_sizes,\n",
    "        edgecolors=node_edgecolors,\n",
    "        linewidths=1.2,\n",
    "        ax=ax\n",
    "    )\n",
    "    nx.draw_networkx_labels(Gp, pos, font_size=7, font_weight=\"bold\", ax=ax)\n",
    "\n",
    "    # Color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=-3, vmax=3))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.7)\n",
    "    cbar.set_label(\"Z-score\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(out_file, dpi=350, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Saved: {out_file}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------\n",
    "# Michael = healthy (all z = 0)\n",
    "# ------------------------------------------\n",
    "z_michael = pd.Series(0.0, index=z_patient.index)\n",
    "\n",
    "plot_single_biovista(\n",
    "    G_var,\n",
    "    z_michael,\n",
    "    var_to_system,\n",
    "    pos_var,\n",
    "    title=\"Biovista Profile — Michael (Healthy)\",\n",
    "    out_file=\"biovista_michael.png\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# Daniel = unhealthy (your simulated patient)\n",
    "# ------------------------------------------\n",
    "z_daniel = z_patient.copy()\n",
    "\n",
    "plot_single_biovista(\n",
    "    G_var,\n",
    "    z_daniel,\n",
    "    var_to_system,\n",
    "    pos_var,\n",
    "    title=\"Biovista Profile — Daniel (Unhealthy)\",\n",
    "    out_file=\"biovista_daniel.png\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535531f9-9f65-49ed-a86f-7998b82cf610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the exact layout already computed for G_var\n",
    "pos = pos_var  # previously computed spring_layout\n",
    "\n",
    "G_empty = nx.Graph()\n",
    "for v in vars_use:\n",
    "    G_empty.add_node(v)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    G_empty,\n",
    "    pos,\n",
    "    node_size=600,\n",
    "    node_color=\"#cccccc\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.8\n",
    ")\n",
    "\n",
    "nx.draw_networkx_labels(\n",
    "    G_empty,\n",
    "    pos,\n",
    "    font_size=8,\n",
    "    font_weight=\"bold\"\n",
    ")\n",
    "\n",
    "plt.title(\"Biovista: Raw Biomarker Universe\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"biovista_nodes_only_same_layout.png\", dpi=350)\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: biovista_nodes_only_same_layout.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038b00e-027a-4523-bb44-b91e772196c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 1. Build empty node-only graph with same nodes\n",
    "# ----------------------------------------------------\n",
    "G_empty = nx.Graph()\n",
    "for v in G_var.nodes():\n",
    "    G_empty.add_node(v)\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# 2. Side-by-side plotting\n",
    "# ----------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(22, 11))\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# LEFT PLOT — Unconnected nodes (\"Before Biovista\")\n",
    "# ----------------------------------------------------\n",
    "nx.draw_networkx_nodes(\n",
    "    G_empty,\n",
    "    pos_var,\n",
    "    node_size=600,\n",
    "    node_color=\"#bfbfbf\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=0.8,\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "nx.draw_networkx_labels(\n",
    "    G_empty,\n",
    "    pos_var,\n",
    "    font_size=7,\n",
    "    font_weight=\"bold\",\n",
    "    ax=axes[0]\n",
    ")\n",
    "\n",
    "axes[0].set_title(\"Before Biovista: Biomarkers Without Connections\", fontsize=16)\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# RIGHT PLOT — Full Biovista network (\"After Biovista\")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Node colors based on z-scores\n",
    "z_vals = np.array([z_patient.get(n, 0.0) for n in G_var.nodes()])\n",
    "z_clipped = np.clip(z_vals, -3, 3)\n",
    "node_colors = plt.cm.coolwarm((z_clipped + 3) / 6)\n",
    "node_sizes = 250 + 600 * np.abs(z_clipped)\n",
    "\n",
    "# Node outline colors based on system membership\n",
    "node_edgecolors = [\n",
    "    system_color_map.get(G_var.nodes[n][\"system\"], \"#7f8c8d\")\n",
    "    for n in G_var.nodes()\n",
    "]\n",
    "\n",
    "# Edge widths scaled by partial correlation strength\n",
    "edge_widths = [\n",
    "    0.4 + 3.0 * abs(d.get(\"weight\", 0.05))\n",
    "    for (_, _, d) in G_var.edges(data=True)\n",
    "]\n",
    "\n",
    "nx.draw_networkx_edges(\n",
    "    G_var,\n",
    "    pos_var,\n",
    "    width=edge_widths,\n",
    "    alpha=0.30,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "nx.draw_networkx_nodes(\n",
    "    G_var,\n",
    "    pos_var,\n",
    "    node_color=node_colors,\n",
    "    node_size=node_sizes,\n",
    "    edgecolors=node_edgecolors,\n",
    "    linewidths=1.2,\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "nx.draw_networkx_labels(\n",
    "    G_var,\n",
    "    pos_var,\n",
    "    font_size=7,\n",
    "    font_weight=\"bold\",\n",
    "    ax=axes[1]\n",
    ")\n",
    "\n",
    "axes[1].set_title(\"After Biovista: Connected Physiologic Network\", fontsize=16)\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"biovista_before_after_side_by_side.png\", dpi=350, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b57d8-a066-43b8-9217-3df28e08831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a systems coherence index\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def compute_SCI(\n",
    "    edges,\n",
    "    node_system,\n",
    "    df_ref,\n",
    "    D_max=None,\n",
    "    sigma_floor=0.02,\n",
    "    min_pairs_for_SCI=3\n",
    "):\n",
    "    \"\"\"\n",
    "    System Coherence Index (SCI v1.1)\n",
    "\n",
    "    Changes vs v1.0:\n",
    "    - Skips domain pairs with sigma == 0 in the NHANES reference (no information).\n",
    "    - Floors very small sigma values at `sigma_floor` to avoid exploding z-scores.\n",
    "    - Optionally computes D_max from df_ref if not provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    edges : pd.DataFrame\n",
    "        Columns = ['i','j','weight'] (patient's edge weights).\n",
    "        In your current setup, weight = |z_i * z_j| for the patient.\n",
    "    node_system : dict\n",
    "        Mapping from node_id -> system label (e.g., 'Metabolic', 'Immune', etc.).\n",
    "    df_ref : pd.DataFrame\n",
    "        NHANES domain-pair reference with columns:\n",
    "        ['system_A','system_B','mu','sigma'].\n",
    "    D_max : float or None, default None\n",
    "        Upper threshold for deviation D. If None, will be estimated from df_ref.\n",
    "    sigma_floor : float, default 0.02\n",
    "        Minimum allowed sigma for valid domain pairs.\n",
    "    min_pairs_for_SCI : int, default 3\n",
    "        Minimum number of valid domain pairs required to compute SCI.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SCI : float\n",
    "        System Coherence Index on a 0–100 scale.\n",
    "    details : dict\n",
    "        {\n",
    "          'df_domain_pairs': DataFrame with W_patient, mu, sigma, sigma_eff, z_AB, valid,\n",
    "          'D': D,\n",
    "          'D_max_used': D_max_used,\n",
    "          'SCI_raw': SCI_raw,\n",
    "          'SCI': SCI,\n",
    "          'n_valid_pairs': n_valid\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 1. Identify systems\n",
    "    # ----------------------------------------------------\n",
    "    systems = sorted(set(node_system.values()))\n",
    "    pairs = [(a, b) for a, b in itertools.combinations(systems, 2)]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 2. Compute W_AB (mean |weight| for each domain pair)\n",
    "    # ----------------------------------------------------\n",
    "    for A, B in pairs:\n",
    "        mask = edges.apply(\n",
    "            lambda r: (node_system[r['i']] == A and node_system[r['j']] == B) or\n",
    "                      (node_system[r['i']] == B and node_system[r['j']] == A),\n",
    "            axis=1\n",
    "        )\n",
    "        w = edges.loc[mask, 'weight'].abs()\n",
    "        W_AB = w.mean() if len(w) > 0 else 0.0\n",
    "\n",
    "        rows.append({'system_A': A, 'system_B': B, 'W_patient': W_AB})\n",
    "\n",
    "    df_patient = pd.DataFrame(rows)\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 3. Attach NHANES reference (mu, sigma)\n",
    "    # ----------------------------------------------------\n",
    "    df = df_patient.merge(df_ref, on=['system_A','system_B'], how='left')\n",
    "\n",
    "    # Raw sigma from NHANES\n",
    "    df['sigma_raw'] = df['sigma']\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 4. Define effective sigma and valid pairs\n",
    "    #    - valid if sigma_raw > 0\n",
    "    #    - floor sigma at sigma_floor\n",
    "    # ----------------------------------------------------\n",
    "    df['valid'] = df['sigma_raw'] > 0\n",
    "\n",
    "    df['sigma_eff'] = np.where(\n",
    "        (df['sigma_raw'] > 0) & (df['sigma_raw'] < sigma_floor),\n",
    "        sigma_floor,\n",
    "        df['sigma_raw']\n",
    "    )\n",
    "    # For zero/negative sigma, keep NaN in sigma_eff so they get excluded from D\n",
    "    df.loc[~df['valid'], 'sigma_eff'] = np.nan\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 5. Compute z_AB for valid pairs only\n",
    "    # ----------------------------------------------------\n",
    "    df['z_AB'] = (df['W_patient'] - df['mu']) / df['sigma_eff']\n",
    "    df['z_AB'] = df['z_AB'].fillna(0.0)\n",
    "\n",
    "    df_valid = df[df['sigma_eff'].notna()].copy()\n",
    "    n_valid = len(df_valid)\n",
    "\n",
    "    if n_valid == 0:\n",
    "        # No valid pairs at all → cannot compute SCI\n",
    "        details = {\n",
    "            'df_domain_pairs': df,\n",
    "            'D': np.nan,\n",
    "            'D_max_used': np.nan,\n",
    "            'SCI_raw': 0.0,\n",
    "            'SCI': 0.0,\n",
    "            'n_valid_pairs': 0\n",
    "        }\n",
    "        return 0.0, details\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 6. Compute D = mean(z^2) over valid pairs\n",
    "    # ----------------------------------------------------\n",
    "    D = float((df_valid['z_AB'] ** 2).mean())\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 7. If D_max not provided, estimate from df_ref\n",
    "    #    using the same sigma_floor logic\n",
    "    # ----------------------------------------------------\n",
    "    if D_max is None:\n",
    "        ref = df_ref.copy()\n",
    "        ref['valid'] = ref['sigma'] > 0\n",
    "        ref['sigma_eff'] = np.where(\n",
    "            (ref['sigma'] > 0) & (ref['sigma'] < sigma_floor),\n",
    "            sigma_floor,\n",
    "            ref['sigma']\n",
    "        )\n",
    "        ref = ref[ref['sigma_eff'].notna()]\n",
    "        if len(ref) > 0:\n",
    "            ref['z_ref'] = ref['mu'] / ref['sigma_eff']\n",
    "            D_max = float(np.percentile((ref['z_ref'] ** 2), 95))\n",
    "        else:\n",
    "            D_max = 1.0  # fallback\n",
    "\n",
    "    D_max_used = D_max if D_max is not None and D_max > 0 else 1.0\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 8. Map D -> SCI (0–100)\n",
    "    # ----------------------------------------------------\n",
    "    SCI_raw = 1 - min(1.0, np.sqrt(D) / np.sqrt(D_max_used))\n",
    "    SCI = 100.0 * SCI_raw\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "    # 9. Package details\n",
    "    # ----------------------------------------------------\n",
    "    details = {\n",
    "        'df_domain_pairs': df,\n",
    "        'D': D,\n",
    "        'D_max_used': D_max_used,\n",
    "        'SCI_raw': SCI_raw,\n",
    "        'SCI': SCI,\n",
    "        'n_valid_pairs': n_valid\n",
    "    }\n",
    "\n",
    "    return SCI, details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa46da6-b601-41d9-ba74-45fe33225155",
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a900c-3c3c-4e6d-b8d7-817978b4f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user supplied information step 1 - build an NHANES reference for SCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2969a-5967-4fd6-af5e-06e2ff6ca3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def build_domain_reference_table(partial_corr, var_to_system):\n",
    "    \"\"\"\n",
    "    Build NHANES domain-domain reference table:\n",
    "    system_A | system_B | mu | sigma\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Convert partial_corr to DataFrame\n",
    "    df_pc = pd.DataFrame(\n",
    "        partial_corr, \n",
    "        index=list(var_to_system.keys()),\n",
    "        columns=list(var_to_system.keys())\n",
    "    )\n",
    "\n",
    "    variables = list(var_to_system.keys())\n",
    "    systems = sorted(set(var_to_system.values()))\n",
    "    pairs = list(itertools.combinations(systems, 2))\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for A, B in pairs:\n",
    "        weights = []\n",
    "        for i, j in itertools.combinations(variables, 2):\n",
    "            si, sj = var_to_system[i], var_to_system[j]\n",
    "            if {si, sj} == {A, B}:\n",
    "                weights.append(abs(df_pc.loc[i, j]))\n",
    "\n",
    "        if len(weights) > 0:\n",
    "            mu = np.mean(weights)\n",
    "            sigma = np.std(weights, ddof=1)\n",
    "        else:\n",
    "            mu = 0.0\n",
    "            sigma = 1e-6   # avoid zero variance\n",
    "\n",
    "        rows.append({\n",
    "            'system_A': A,\n",
    "            'system_B': B,\n",
    "            'mu': mu,\n",
    "            'sigma': sigma\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Correct function call\n",
    "df_ref = build_domain_reference_table(partial_corr, var_to_system)\n",
    "\n",
    "df_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8b6f2-0dbf-4f91-b82a-bf45a685ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_adj = df_ref.copy()\n",
    "df_ref_adj['sigma'] = df_ref_adj['sigma'].replace(0, 1e-6)\n",
    "\n",
    "D_max = np.percentile((df_ref_adj['mu'] / df_ref_adj['sigma'])**2, 95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321addb-2549-4cb7-920d-4a45ca697bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI, details = compute_SCI(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=D_max\n",
    ")\n",
    "\n",
    "SCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cae2fd-2030-4c0a-9f0e-b9a8f5e89d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient specific edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3bfde7-6f2b-4d54-af1e-273822edf942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def build_patient_edges(z_patient):\n",
    "    rows = []\n",
    "    variables = z_patient.index\n",
    "    \n",
    "    for i, j in itertools.combinations(variables, 2):\n",
    "        w = abs(z_patient[i] * z_patient[j])\n",
    "        rows.append({'i': i, 'j': j, 'weight': w})\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_edges_patient = build_patient_edges(z_patient)   # z_patient already exists in your vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dc8f37-d74b-4d4f-ad4a-1144a39b8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure df_edges_patient exists (from z_patient → |z_i*z_j| edges)\n",
    "SCI, details = compute_SCI(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,      # your 66-row NHANES table\n",
    "    D_max=None          # let v1.1 auto-compute a reasonable D_max\n",
    ")\n",
    "\n",
    "SCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee24664-e094-41a2-9de0-75584ce32fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a81a065-d185-4f74-88a5-2eb6584d8e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5951e-66a8-4880-9d90-a1d61ad9fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "details['df_domain_pairs'][['system_A','system_B','W_patient','mu','sigma_raw','sigma_eff','z_AB','valid']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01f43cc-cb54-4d61-9900-721b71598d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build patient edges with tanh scaling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def build_patient_edges_tanh(z_patient, partial_corr):\n",
    "    \"\"\"\n",
    "    Build patient-specific edge list using:\n",
    "        w_ij = |rho_ij| * tanh(|z_i * z_j|)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_patient : pd.Series\n",
    "        Index = variable names, values = patient z-scores.\n",
    "    partial_corr : np.ndarray\n",
    "        NHANES partial correlation matrix (same variables, same order).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_edges_patient : pd.DataFrame\n",
    "        Columns ['i','j','weight']\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure rows/cols are labeled by variable names\n",
    "    variables = list(z_patient.index)\n",
    "    df_pc = pd.DataFrame(partial_corr, index=variables, columns=variables)\n",
    "\n",
    "    rows = []\n",
    "    for i, j in itertools.combinations(variables, 2):\n",
    "        rho_ij = df_pc.loc[i, j]\n",
    "        z_i = z_patient[i]\n",
    "        z_j = z_patient[j]\n",
    "\n",
    "        mod = np.tanh(abs(z_i * z_j))          # in (0,1)\n",
    "        w = abs(rho_ij) * mod                  # bounded by |rho_ij|\n",
    "\n",
    "        rows.append({'i': i, 'j': j, 'weight': w})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Build new patient edge list\n",
    "df_edges_patient = build_patient_edges_tanh(z_patient, partial_corr)\n",
    "\n",
    "df_edges_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995cd81-e15b-4dac-a61b-a41a396e2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def build_patient_edges_blended(z_patient, partial_corr, blend=0.5):\n",
    "    \"\"\"\n",
    "    Build patient edges using:\n",
    "        w_ij = blend * |rho_ij| + (1-blend) * tanh(|z_i * z_j|)\n",
    "    This preserves NHANES topology AND patient-specific signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_patient : pd.Series\n",
    "    partial_corr : np.ndarray\n",
    "    blend : float in [0,1]\n",
    "        0.5 = equal weight to NHANES and patient modulation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with ['i','j','weight']\n",
    "    \"\"\"\n",
    "\n",
    "    variables = list(z_patient.index)\n",
    "    df_pc = pd.DataFrame(partial_corr, index=variables, columns=variables)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for i, j in itertools.combinations(variables, 2):\n",
    "        rho = abs(df_pc.loc[i, j])\n",
    "        mod = np.tanh(abs(z_patient[i] * z_patient[j]))\n",
    "\n",
    "        w = blend * rho + (1 - blend) * mod\n",
    "        rows.append({'i': i, 'j': j, 'weight': w})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_edges_patient = build_patient_edges_blended(z_patient, partial_corr, blend=0.5)\n",
    "\n",
    "df_edges_patient.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e189a-d04b-417c-b665-34abcfd5c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI, details = compute_SCI(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=None   # Let SCI auto-estimate\n",
    ")\n",
    "\n",
    "SCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0d8bb-8c85-4082-8d7a-ecb91f79eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI, details = compute_SCI(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=25,            # FIXED SCALE, prevents collapse to zero\n",
    "    sigma_floor=0.005    # MUCH safer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba9227-6225-4ae5-a477-492f53b594ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3f8f0-cbe4-493c-9e06-d6a8526ecacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "details['D'], details['D_max_used'], details['n_valid_pairs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129b6df-a535-4c72-b03a-a114f913e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "details['df_domain_pairs'][['system_A','system_B','W_patient','mu','sigma_eff','z_AB']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce335e49-abff-4d1c-9d9a-d7fa735094c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SCI_v20(\n",
    "    edges,\n",
    "    node_system,\n",
    "    df_ref,\n",
    "    D_max=25,\n",
    "    z_cap=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Robust System Coherence Index (SCI v2.0)\n",
    "    - caps extreme z-values\n",
    "    - uses median z² instead of mean z²\n",
    "    - uses median sigma to stabilize tiny-variance pairs\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import itertools\n",
    "\n",
    "    # Identify systems\n",
    "    systems = sorted(set(node_system.values()))\n",
    "    pairs = [(a, b) for a, b in itertools.combinations(systems, 2)]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # Compute W_patient for each domain pair\n",
    "    for A, B in pairs:\n",
    "        mask = edges.apply(\n",
    "            lambda r: (node_system[r['i']] == A and node_system[r['j']] == B) or\n",
    "                      (node_system[r['i']] == B and node_system[r['j']] == A),\n",
    "            axis=1\n",
    "        )\n",
    "        w = edges.loc[mask, 'weight'].abs()\n",
    "        W_AB = w.mean() if len(w) else 0.0\n",
    "\n",
    "        rows.append({'system_A': A, 'system_B': B, 'W_patient': W_AB})\n",
    "\n",
    "    df = pd.DataFrame(rows).merge(df_ref, on=['system_A','system_B'], how='left')\n",
    "\n",
    "    # Determine a stable sigma floor\n",
    "    median_sigma = df_ref[df_ref['sigma'] > 0]['sigma'].median()\n",
    "    df['sigma_eff'] = df['sigma'].copy()\n",
    "    df['sigma_eff'] = df['sigma_eff'].replace(0, median_sigma)\n",
    "    df['sigma_eff'] = df['sigma_eff'].fillna(median_sigma)\n",
    "\n",
    "    # Compute z_AB with cap\n",
    "    df['z_AB'] = (df['W_patient'] - df['mu']) / df['sigma_eff']\n",
    "    df['z_AB'] = df['z_AB'].clip(-z_cap, z_cap)\n",
    "\n",
    "    # Robust D = median of z_AB²\n",
    "    df['z2'] = df['z_AB']**2\n",
    "    D = float(df['z2'].median())\n",
    "\n",
    "    # Map D to SCI\n",
    "    SCI_raw = 1 - min(1.0, np.sqrt(D) / np.sqrt(D_max))\n",
    "    SCI = 100 * SCI_raw\n",
    "\n",
    "    return SCI, {\n",
    "        'D': D,\n",
    "        'D_max': D_max,\n",
    "        'df_domain_pairs': df,\n",
    "        'SCI_raw': SCI_raw,\n",
    "        'SCI': SCI\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd29072a-0b9e-4a53-bcb1-f404d274f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI2, details2 = compute_SCI_v20(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref\n",
    ")\n",
    "\n",
    "SCI2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e43039-fc7c-4ab4-a725-fa28955c1d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "details2['D'], details2['SCI']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858de91e-29f7-497b-8d73-f14d8286bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI2, details2 = compute_SCI_v20(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=400   # <-- key change\n",
    ")\n",
    "\n",
    "SCI2, details2['D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb677f-e01e-478a-85d8-d4d11ca7588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def build_patient_edges_blended(z_vals, partial_corr, blend=0.5):\n",
    "    \"\"\"\n",
    "    Build patient edges using:\n",
    "        w_ij = blend * |rho_ij| + (1-blend) * tanh(|z_i * z_j|)\n",
    "    \"\"\"\n",
    "    variables = list(z_vals.index)\n",
    "    df_pc = pd.DataFrame(partial_corr, index=variables, columns=variables)\n",
    "\n",
    "    rows = []\n",
    "    for i, j in itertools.combinations(variables, 2):\n",
    "        rho = abs(df_pc.loc[i, j])\n",
    "        mod = np.tanh(abs(z_vals[i] * z_vals[j]))\n",
    "        w = blend * rho + (1 - blend) * mod\n",
    "        rows.append({'i': i, 'j': j, 'weight': w})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def compute_SCI_v20(edges, node_system, df_ref, D_max, z_cap=10):\n",
    "    \"\"\"\n",
    "    Compute robust D for a single individual (NHANES or patient).\n",
    "    Returns SCI and details, but for D_max calibration we only care about D.\n",
    "    \"\"\"\n",
    "    systems = sorted(set(node_system.values()))\n",
    "    pairs = [(a, b) for a, b in itertools.combinations(systems, 2)]\n",
    "\n",
    "    rows = []\n",
    "    for A, B in pairs:\n",
    "        mask = edges.apply(\n",
    "            lambda r: ((node_system[r['i']] == A and node_system[r['j']] == B) or\n",
    "                       (node_system[r['i']] == B and node_system[r['j']] == A)),\n",
    "            axis=1\n",
    "        )\n",
    "        w = edges.loc[mask, 'weight'].abs()\n",
    "        W_AB = w.mean() if len(w) else 0.0\n",
    "        rows.append({'system_A': A, 'system_B': B, 'W_patient': W_AB})\n",
    "\n",
    "    df = pd.DataFrame(rows).merge(df_ref, on=['system_A','system_B'], how='left')\n",
    "\n",
    "    median_sigma = df_ref[df_ref['sigma'] > 0]['sigma'].median()\n",
    "\n",
    "    df['sigma_eff'] = df['sigma'].copy()\n",
    "    df['sigma_eff'] = df['sigma_eff'].replace(0, median_sigma)\n",
    "    df['sigma_eff'] = df['sigma_eff'].fillna(median_sigma)\n",
    "\n",
    "    df['z_AB'] = (df['W_patient'] - df['mu']) / df['sigma_eff']\n",
    "    df['z_AB'] = df['z_AB'].clip(-z_cap, z_cap)\n",
    "\n",
    "    df['z2'] = df['z_AB'] ** 2\n",
    "    D = float(df['z2'].median())   # robust deviation\n",
    "\n",
    "    SCI_raw = 1 - min(1.0, np.sqrt(D) / np.sqrt(D_max))\n",
    "    SCI = 100 * SCI_raw\n",
    "\n",
    "    return SCI, {'D': D}\n",
    "    \n",
    "\n",
    "def compute_Dmax_from_NHANES(X_std, partial_corr, var_to_system, df_ref, sample_size=3000):\n",
    "    \"\"\"\n",
    "    Compute an empirically calibrated D_max from NHANES.\n",
    "    \"\"\"\n",
    "    n = X_std.shape[0]\n",
    "    idx = np.random.choice(n, size=min(sample_size, n), replace=False)\n",
    "\n",
    "    variables = list(var_to_system.keys())\n",
    "    df_X = pd.DataFrame(X_std, columns=variables)\n",
    "\n",
    "    D_list = []\n",
    "\n",
    "    for k in idx:\n",
    "        z_row = df_X.iloc[k]                      # NHANES individual's z-scores\n",
    "        edges_k = build_patient_edges_blended(\n",
    "            z_row,\n",
    "            partial_corr,\n",
    "            blend=0.5\n",
    "        )\n",
    "        _, det = compute_SCI_v20(\n",
    "            edges=edges_k,\n",
    "            node_system=var_to_system,\n",
    "            df_ref=df_ref,\n",
    "            D_max=999999     # large placeholder; we only want det['D']\n",
    "        )\n",
    "        D_list.append(det['D'])\n",
    "\n",
    "    D_array = np.array(D_list)\n",
    "    D_max = float(np.percentile(D_array, 95))\n",
    "\n",
    "    return D_max, D_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a69ab9-8624-4a27-9e9b-6e744e62711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code takes a long time to run\n",
    "D_max, D_vals = compute_Dmax_from_NHANES(\n",
    "    X_std=X_std,\n",
    "    partial_corr=partial_corr,\n",
    "    var_to_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    sample_size=3000\n",
    ")\n",
    "\n",
    "D_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddad82-d68d-4ba5-9505-c5ba8564580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25035b5-4cc8-4824-83b4-cd130b97b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(D_vals, [5,25,50,75,95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02d7f48-e61b-45f6-be1b-c07a34aff9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCI_final, details_final = compute_SCI_v20(\n",
    "    edges=df_edges_patient,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=100         # <--- calibrated value\n",
    ")\n",
    "\n",
    "SCI_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab9149-0962-492f-afbd-6fceabd894ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_final['D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b83822-7816-462d-b97e-bf0c1aaeb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SCI for 20 nhanes individuals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# How many NHANES individuals to inspect\n",
    "n_sample = 20\n",
    "\n",
    "variables = list(var_to_system.keys())\n",
    "df_X = pd.DataFrame(X_std, columns=variables)\n",
    "\n",
    "# Randomly sample row indices\n",
    "idx_sample = np.random.choice(df_X.index, size=n_sample, replace=False)\n",
    "\n",
    "sci_list = []\n",
    "D_list = []\n",
    "\n",
    "for k in idx_sample:\n",
    "    z_row = df_X.loc[k]\n",
    "\n",
    "    # Build NHANES individual edges using the same blended rule\n",
    "    edges_k = build_patient_edges_blended(z_row, partial_corr, blend=0.5)\n",
    "\n",
    "    # Use calibrated D_max = 100 from your earlier step\n",
    "    SCI_k, det_k = compute_SCI_v20(\n",
    "        edges=edges_k,\n",
    "        node_system=var_to_system,\n",
    "        df_ref=df_ref,\n",
    "        D_max=100\n",
    "    )\n",
    "\n",
    "    sci_list.append(SCI_k)\n",
    "    D_list.append(det_k['D'])\n",
    "\n",
    "df_sci_nhanes = pd.DataFrame({\n",
    "    \"row_index\": idx_sample,\n",
    "    \"SCI_v2\": sci_list,\n",
    "    \"D\": D_list\n",
    "})\n",
    "\n",
    "df_sci_nhanes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ebc74c-d3ec-44de-8d7d-cc6966301f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci_nhanes['SCI_v2'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f743c0c5-3045-4ff2-875d-80ad523640d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sci_nhanes.sort_values('SCI_v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a05c10-6957-4296-8923-9005e148f749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute for daniel and michael\n",
    "# --- Michael ---\n",
    "edges_michael = build_patient_edges_blended(z_Michael, partial_corr, blend=0.5)\n",
    "SCI_michael, details_michael = compute_SCI_v20(\n",
    "    edges=edges_michael,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=100       # <-- calibrated D_max\n",
    ")\n",
    "print(\"Michael SCI_v2.0:\", SCI_michael)\n",
    "print(\"Michael D:\", details_michael['D'])\n",
    "\n",
    "\n",
    "# --- Daniel ---\n",
    "edges_daniel = build_patient_edges_blended(z_Daniel, partial_corr, blend=0.5)\n",
    "SCI_daniel, details_daniel = compute_SCI_v20(\n",
    "    edges=edges_daniel,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=100\n",
    ")\n",
    "print(\"Daniel SCI_v2.0:\", SCI_daniel)\n",
    "print(\"Daniel D:\", details_daniel['D'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047d5294-982b-4158-8a30-63e6420d1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"z_Michael:\")\n",
    "print(z_Michael)\n",
    "\n",
    "print(\"\\nz_Daniel:\")\n",
    "print(z_Daniel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce83927-5a7f-413e-ae9c-29cb3c0584a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# they are flipped. flip them back\n",
    "z_Daniel, z_Michael = z_Michael, z_Daniel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29954848-9bb5-46b0-8a6b-29b8d4763554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Compute Daniel's domain-pair table\n",
    "edges_daniel = build_patient_edges_blended(z_Daniel, partial_corr, blend=0.5)\n",
    "SCI_d, det_d = compute_SCI_v20(\n",
    "    edges=edges_daniel,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=100\n",
    ")\n",
    "\n",
    "df_dp = det_d[\"df_domain_pairs\"]\n",
    "\n",
    "# 2. Pivot into matrix form\n",
    "mat = df_dp.pivot(index=\"system_A\", columns=\"system_B\", values=\"z_AB\")\n",
    "\n",
    "# Because pairs are only upper-triangle, fill symmetric + diagonal\n",
    "mat = mat.copy()\n",
    "for i in mat.index:\n",
    "    for j in mat.columns:\n",
    "        if pd.isna(mat.loc[i,j]) and not pd.isna(mat.loc[j,i]):\n",
    "            mat.loc[i,j] = mat.loc[j,i]\n",
    "        if i == j:\n",
    "            mat.loc[i,j] = 0\n",
    "\n",
    "# 3. Plot\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(mat, aspect='auto')  # default colormap (allowed)\n",
    "plt.xticks(range(len(mat.columns)), mat.columns, rotation=90)\n",
    "plt.yticks(range(len(mat.index)), mat.index)\n",
    "plt.title(\"Daniel – Domain Pair Deviation Heatmap (z_AB)\")\n",
    "plt.colorbar(label=\"z_AB deviation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80834ed9-fe8e-440b-bd59-84ae500b0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SCI_v20(edges, node_system, df_ref, D_max, z_cap=10):\n",
    "    \"\"\"\n",
    "    Robust SCI v2.0:\n",
    "    - median-based D\n",
    "    - z-value clipping\n",
    "    - sigma stabilization\n",
    "    - returns df_domain_pairs (for heatmaps!)\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import itertools\n",
    "\n",
    "    # --- Build domain pairs ---\n",
    "    systems = sorted(set(node_system.values()))\n",
    "    pairs = [(a, b) for a, b in itertools.combinations(systems, 2)]\n",
    "\n",
    "    rows = []\n",
    "    for A, B in pairs:\n",
    "        # All edges where system(i)==A and system(j)==B (or reversed)\n",
    "        mask = edges.apply(\n",
    "            lambda r: ((node_system[r['i']] == A and node_system[r['j']] == B) or\n",
    "                       (node_system[r['i']] == B and node_system[r['j']] == A)),\n",
    "            axis=1\n",
    "        )\n",
    "        w = edges.loc[mask, 'weight'].abs()\n",
    "        W_AB = w.mean() if len(w) else 0.0\n",
    "        rows.append({\n",
    "            'system_A': A,\n",
    "            'system_B': B,\n",
    "            'W_patient': W_AB\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # --- Merge NHANES reference values ---\n",
    "    df = df.merge(df_ref, on=['system_A', 'system_B'], how='left')\n",
    "\n",
    "    # --- Stabilize sigma ---\n",
    "    median_sigma = df_ref[df_ref['sigma'] > 0]['sigma'].median()\n",
    "    df['sigma_eff'] = df['sigma'].copy()\n",
    "    df['sigma_eff'] = df['sigma_eff'].replace(0, median_sigma)\n",
    "    df['sigma_eff'] = df['sigma_eff'].fillna(median_sigma)\n",
    "\n",
    "    # --- Compute z_AB with clipping ---\n",
    "    df['z_AB'] = (df['W_patient'] - df['mu']) / df['sigma_eff']\n",
    "    df['z_AB'] = df['z_AB'].clip(-z_cap, z_cap)\n",
    "\n",
    "    # --- Compute robust deviation ---\n",
    "    df['z2'] = df['z_AB'] ** 2\n",
    "    D = float(df['z2'].median())\n",
    "\n",
    "    # --- Map into SCI ---\n",
    "    SCI_raw = 1 - min(1.0, np.sqrt(D) / np.sqrt(D_max))\n",
    "    SCI = 100 * SCI_raw\n",
    "\n",
    "    return SCI, {\n",
    "        'D': D,\n",
    "        'SCI_raw': SCI_raw,\n",
    "        'SCI': SCI,\n",
    "        'df_domain_pairs': df   # <-- key now included!\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70dac6f-d437-40f3-9369-7d98519a3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_daniel = build_patient_edges_blended(z_Daniel, partial_corr, blend=0.5)\n",
    "SCI_d, det_d = compute_SCI_v20(\n",
    "    edges=edges_daniel,\n",
    "    node_system=var_to_system,\n",
    "    df_ref=df_ref,\n",
    "    D_max=100\n",
    ")\n",
    "\n",
    "df_dp = det_d[\"df_domain_pairs\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8466df-5b8a-4fba-a214-1cc7c781c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pivot into symmetric matrix\n",
    "mat = df_dp.pivot(index=\"system_A\", columns=\"system_B\", values=\"z_AB\")\n",
    "\n",
    "# make symmetric\n",
    "mat = mat.copy()\n",
    "for i in mat.index:\n",
    "    for j in mat.columns:\n",
    "        if pd.isna(mat.loc[i,j]) and not pd.isna(mat.loc[j,i]):\n",
    "            mat.loc[i,j] = mat.loc[j,i]\n",
    "        if i == j:\n",
    "            mat.loc[i,j] = 0\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(mat, aspect='auto')   # default colormap allowed\n",
    "plt.xticks(range(len(mat.columns)), mat.columns, rotation=90)\n",
    "plt.yticks(range(len(mat.index)), mat.index)\n",
    "plt.title(\"Daniel – Domain Pair Deviation Heatmap (z_AB)\")\n",
    "plt.colorbar(label=\"Domain-pair deviation (z_AB)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7320f4-66a0-4967-aa00-67c19b67e0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCI 2.0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Build NHANES domain reference\n",
    "# ---------------------------------------------------------\n",
    "def build_domain_reference_table(partial_corr, var_to_system):\n",
    "    variables = list(var_to_system.keys())\n",
    "    systems = sorted(set(var_to_system.values()))\n",
    "    df_pc = pd.DataFrame(partial_corr, index=variables, columns=variables)\n",
    "    pairs = list(itertools.combinations(systems, 2))\n",
    "\n",
    "    rows = []\n",
    "    for A, B in pairs:\n",
    "        weights = []\n",
    "        for i, j in itertools.combinations(variables, 2):\n",
    "            if {var_to_system[i], var_to_system[j]} == {A, B}:\n",
    "                weights.append(abs(df_pc.loc[i, j]))\n",
    "\n",
    "        if len(weights):\n",
    "            mu = np.mean(weights)\n",
    "            sigma = np.std(weights, ddof=1)\n",
    "        else:\n",
    "            mu, sigma = 0.0, 1e-6\n",
    "\n",
    "        rows.append({\"system_A\": A, \"system_B\": B, \"mu\": mu, \"sigma\": sigma})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_ref = build_domain_reference_table(partial_corr, var_to_system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab069048-fb6a-4551-a9ed-c93827af609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_patient_edges_blended(z_vals, partial_corr, blend=0.5):\n",
    "    variables = list(z_vals.index)\n",
    "    df_pc = pd.DataFrame(partial_corr, index=variables, columns=variables)\n",
    "\n",
    "    rows = []\n",
    "    for i, j in itertools.combinations(variables, 2):\n",
    "        rho = abs(df_pc.loc[i, j])\n",
    "        mod = np.tanh(abs(z_vals[i] * z_vals[j]))\n",
    "        w = blend * rho + (1 - blend) * mod\n",
    "        rows.append({'i': i, 'j': j, 'weight': w})\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2befdda-c764-4d74-a754-0f44613c6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SCI_v20(edges, node_system, df_ref, D_max=100, z_cap=10):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import itertools\n",
    "\n",
    "    systems = sorted(set(node_system.values()))\n",
    "    pairs = [(a,b) for a,b in itertools.combinations(systems,2)]\n",
    "\n",
    "    # ---- Domain pairs table ----\n",
    "    rows = []\n",
    "    for A,B in pairs:\n",
    "        mask = edges.apply(\n",
    "            lambda r: ((node_system[r['i']] == A and node_system[r['j']] == B) or\n",
    "                       (node_system[r['i']] == B and node_system[r['j']] == A)),\n",
    "            axis=1\n",
    "        )\n",
    "        w = edges.loc[mask, 'weight'].abs()\n",
    "        W_AB = w.mean() if len(w) else 0.0\n",
    "        rows.append({\"system_A\":A, \"system_B\":B, \"W_patient\":W_AB})\n",
    "\n",
    "    df = pd.DataFrame(rows).merge(df_ref, on=[\"system_A\",\"system_B\"], how=\"left\")\n",
    "\n",
    "    # ---- Stabilize sigma ----\n",
    "    median_sigma = df_ref[df_ref[\"sigma\"]>0][\"sigma\"].median()\n",
    "    df[\"sigma_eff\"] = df[\"sigma\"].replace(0, median_sigma).fillna(median_sigma)\n",
    "\n",
    "    # ---- Compute clipped z ----\n",
    "    df[\"z_AB\"] = ((df[\"W_patient\"] - df[\"mu\"]) / df[\"sigma_eff\"]).clip(-z_cap, z_cap)\n",
    "\n",
    "    # ---- Robust deviation ----\n",
    "    df[\"z2\"] = df[\"z_AB\"]**2\n",
    "    D = float(df[\"z2\"].median())\n",
    "\n",
    "    # ---- SCI mapping ----\n",
    "    SCI_raw = 1 - min(1.0, np.sqrt(D) / np.sqrt(D_max))\n",
    "    SCI = 100 * SCI_raw\n",
    "\n",
    "    return SCI, {\n",
    "        \"D\": D,\n",
    "        \"SCI_raw\": SCI_raw,\n",
    "        \"SCI\": SCI,\n",
    "        \"df_domain_pairs\": df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea4397-4a04-48d4-82e2-4f1e06750da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Dmax_from_NHANES(X_std, partial_corr, var_to_system, df_ref, sample_size=3000):\n",
    "    variables = list(var_to_system.keys())\n",
    "    df_X = pd.DataFrame(X_std, columns=variables)\n",
    "\n",
    "    idx = np.random.choice(df_X.index, size=min(sample_size, len(df_X)), replace=False)\n",
    "    D_vals = []\n",
    "\n",
    "    for k in idx:\n",
    "        z = df_X.loc[k]\n",
    "        edges = build_patient_edges_blended(z, partial_corr, blend=0.5)\n",
    "        _, det = compute_SCI_v20(edges, var_to_system, df_ref, D_max=10**9)\n",
    "        D_vals.append(det[\"D\"])\n",
    "\n",
    "    return float(np.percentile(D_vals, 95)), np.array(D_vals)\n",
    "\n",
    "# Run once\n",
    "D_max, D_vals = compute_Dmax_from_NHANES(X_std, partial_corr, var_to_system, df_ref)\n",
    "\n",
    "print(\"Calibrated D_max =\", D_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6aa31-bddd-4f15-86bb-7db9abc4f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"D_max_calibrated.npy\", D_max)\n",
    "# D_max = float(np.load(\"D_max_calibrated.npy\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500efd5-7819-48f3-9083-5bb2917d0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_michael = build_patient_edges_blended(z_Michael, partial_corr, blend=0.5)\n",
    "SCI_m, det_m = compute_SCI_v20(edges_michael, var_to_system, df_ref, D_max)\n",
    "\n",
    "edges_daniel = build_patient_edges_blended(z_Daniel, partial_corr, blend=0.5)\n",
    "SCI_d, det_d = compute_SCI_v20(edges_daniel, var_to_system, df_ref, D_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee24be-55fb-402e-bc00-b8fab0148b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dp = det_d[\"df_domain_pairs\"]\n",
    "\n",
    "mat = df_dp.pivot(index=\"system_A\", columns=\"system_B\", values=\"z_AB\")\n",
    "mat = mat.copy()\n",
    "\n",
    "# Symmetrize & fill diagonal\n",
    "for i in mat.index:\n",
    "    for j in mat.columns:\n",
    "        if pd.isna(mat.loc[i,j]) and not pd.isna(mat.loc[j,i]):\n",
    "            mat.loc[i,j] = mat.loc[j,i]\n",
    "        if i == j:\n",
    "            mat.loc[i,j] = 0\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(mat, aspect='auto')\n",
    "plt.xticks(range(len(mat.columns)), mat.columns, rotation=90)\n",
    "plt.yticks(range(len(mat.index)), mat.index)\n",
    "plt.title(\"Domain Pair Deviation Heatmap\")\n",
    "plt.colorbar(label=\"z_AB deviation\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
